mapper.py
import sys
for line in sys.stdin:
line = line.strip()
words = line.split()
for word in words:
print('%s\t%s' % (word, 1))



reducer.py


fromoperator import itemgetter
import sys
current_word = None
current_count = 0
word = None
for line in sys.stdin:
line = line.strip()
word, count = line.split('\t', 1)
try:
count = int(count)
except ValueError:
Dept of AIML,GAT 10 BDA Lab â€“ 22AML54
continue
if current_word == word:
current_count += count
else:
if current_word:
print('%s\t%s' % (current_word, current_count))
current_count = count
current_word = word
if current_word == word:
print('%s\t%s' % (current_word, current_count))


Step 3. Run the map-reduce word count program on UNIX platform
$cat input.txt | python3 mapper.py |sort | python3 reducer.py
Step 4. Run the map-reduce word count program on Hadoop
1. $sudo su hduser
2. $ start-dfs.sh
3. $start-yarn.sh
4. $jps
5. $hafs dfs -put /input.txt /
6. hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming 3.3.4.jar -files
./mapper.py,./reducer.py -mapper "python3 mapper.py" -reducer "python3 reducer.py" -input
/5000-8.txt -output /0000009
7. Observe the result in localhost:port_number
8. Download outputfile and view it for wordcount
